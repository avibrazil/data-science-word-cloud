{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bc6d6d6-ca23-4511-bd53-861f470c75da",
   "metadata": {},
   "source": [
    "# Make a Word Cloud from Data Science terms\n",
    "\n",
    "We will list terms with their weight, configure a word cloud, display and save as SVG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01db14a0-cf3b-462f-8dd8-7c49925a92d1",
   "metadata": {},
   "source": [
    "## Word Cloud parameters\n",
    "\n",
    "[Documentation for the Wordcloud class can be found here.](https://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html#wordcloud.WordCloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07000c6-a976-41cb-ae1a-fed308ff5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_config = dict(\n",
    "    max_words=2000,\n",
    "\n",
    "    max_font_size=100,\n",
    "    width=1600,\n",
    "    height=900,\n",
    "    prefer_horizontal=0.5,\n",
    "    font_step=1,\n",
    "    mode='RGBA',\n",
    "    background_color=None,\n",
    "    random_state=42,\n",
    "\n",
    "    # 0 means the frequencies in the data are reflected less\n",
    "    # acurately but it makes a better picture\n",
    "    relative_scaling=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf254d5-2616-42ec-ad91-15ac789c2c12",
   "metadata": {},
   "source": [
    "## Data Science terms for the word cloud\n",
    "We are breaking in categories only because we are obsessed with data classification.\n",
    "\n",
    "The weight controls the size of the terms in the cloud. Maximum size is 10. Terms with no weight will be filled by a random numbers up to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab634bd0-efe7-446c-b995-220dc3646e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#       (weight,     term)\n",
    "terms = dict(\n",
    "    Algorithm = [\n",
    "        (None,      'Decision Tree'),\n",
    "        (None,      'Gradient Boosting'),\n",
    "        (None,      'Hierarchical Clustering'),\n",
    "        (None,      'Naive Bayes'),\n",
    "        (None,      'Ensembles'),\n",
    "        (None,      'Hyper-parameters'),\n",
    "        (None,      'K-Means'),\n",
    "        (None,      'Regression'),\n",
    "        (None,      'ElasticNet'),\n",
    "        (None,      'Classification'),\n",
    "        (None,      'Logit'),\n",
    "        (None,      'fit()'),\n",
    "        (None,      'predict()'),\n",
    "        (None,      'Optuna'),\n",
    "        (10,        'Random Forest'),\n",
    "        (None,      'Support Vector Machine'),\n",
    "        (10,        'XGBoost'),\n",
    "        (None,      'ARIMA'),\n",
    "        (None,      'Neural Network'),\n",
    "    ],\n",
    "    Concept = [\n",
    "        (None,      'Artificial Intelligence'),\n",
    "        (None,      'Data Pipeline'),\n",
    "        (10,        'Machine Learning'),\n",
    "        (None,      'Predictive Analytics'),\n",
    "        (None,      'Supervised learning'),\n",
    "        (None,      'Unsupervised learning'),\n",
    "        (None,      'Time series'),\n",
    "        (10,        'Ŷ'),\n",
    "    ],\n",
    "    Format = [\n",
    "        (None,      'CSV'),\n",
    "        (None,      'JSON'),\n",
    "        (10,        'Parquet'),\n",
    "        (None,      'Pickle'),\n",
    "    ],\n",
    "    Library = [\n",
    "        (None,      'BeautifulSoup'),\n",
    "        (None,      'Matplotlib'),\n",
    "        (None,      'NumPy'),\n",
    "        (10,        'Pandas'),\n",
    "        (10,        'Scikit Learn'),\n",
    "        (None,      'SciPy'),\n",
    "        (None,      'Seaborn'),\n",
    "        (None,      'Tensor Flow'),\n",
    "    ],\n",
    "    Metric = [\n",
    "        (None,      'Accuracy'),\n",
    "        (None,      'Confusion Matrix'),\n",
    "        (None,      'True positive'),\n",
    "        (None,      'True negative'),\n",
    "        (None,      'False positive'),\n",
    "        (None,      'False negative'),\n",
    "        (10,        'Correlation Matrix'),\n",
    "        (None,      'Kolmogorov-Smirnov'),\n",
    "        (9,         'F1 Score'),\n",
    "        (None,      'Precision'),\n",
    "        (None,      'Quantile'),\n",
    "        (None,      'Recall'),\n",
    "        (9,         'ROC Curve'),\n",
    "        (None,      'Area under curve'),\n",
    "        (None,      'Average'),\n",
    "        (None,      'Median'),\n",
    "        (None,      'Mean squared error'),\n",
    "        (None,      'Mean squared logarithmic error'),\n",
    "        (10,        'R²'),\n",
    "        (None,      'Covariance'),\n",
    "    ],\n",
    "    Practice = [\n",
    "        (None,      'Feature engineering'),\n",
    "        (None,      'Feature selection'),\n",
    "        (None,      'Hypothesis testing'),\n",
    "        (None,      'Aggregation'),\n",
    "        (None,      'Anonymization'),\n",
    "        (None,      'Data cleansing'),\n",
    "        (None,      'Data augmentation'),\n",
    "        (None,      'Compression'),\n",
    "        (None,      'Decryption'),\n",
    "        (None,      'Encryption'),\n",
    "        (None,      'Data Enrichment'),\n",
    "        (None,      'Ethics'),\n",
    "        (None,      'Normalization'),\n",
    "        (None,      'Quality'),\n",
    "        (None,      'Replication'),\n",
    "        (9,         'Token'),\n",
    "        (None,      'Data wrangling'),\n",
    "        (None,      'Feature Engineering'),\n",
    "        (None,      'Missing Data Imputation'),\n",
    "        (None,      'Model Evaluation'),\n",
    "        (None,      'Outlier'),\n",
    "        (None,      'Train-Test Split'),\n",
    "        (None,      'Stratified KFold'),\n",
    "        (None,      'Web scraping'),\n",
    "    ],\n",
    "    Process = [\n",
    "        (None,      'ETL'),\n",
    "        (None,      'Batch processing'),\n",
    "        (None,      'Cross validation'),\n",
    "        (10,        'Drift detection'),\n",
    "    ],\n",
    "    Technique = [\n",
    "        (None,      'Clustering'),\n",
    "        (None,      'Principal Component Analysis'),\n",
    "        (None,      'One-hot encoding'),\n",
    "    ],\n",
    "    Tool = [\n",
    "        (None,      'Big Data'),\n",
    "        (None,      'Data Lake'),\n",
    "        (None,      'API'),\n",
    "        (None,      'Data Catalog'),\n",
    "        (10,        'Jupyter Notebook'),\n",
    "        (None,      'Spark'),\n",
    "        (9,         'SQL'),\n",
    "        (None,      'Logarithm'),\n",
    "        (None,      'BoxCox'),\n",
    "    ],\n",
    "    Visualization = [\n",
    "        (None,      'Box plot'),\n",
    "        (None,      'Histogram'),\n",
    "        (9,         'Gaussian distribution'),\n",
    "        (10,        'Normal distribution'),\n",
    "        (None,      'Scatter plot'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066f68c-3a75-4cae-a0fa-2eb38136b375",
   "metadata": {},
   "source": [
    "## Logic to make the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e2cdd9-8e7f-4d68-a479-697733ab24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy\n",
    "import pandas\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1335c87-3ed2-48ef-9128-4cc2a5e56c06",
   "metadata": {},
   "source": [
    "Fill the gaps and convert it something usable by wordcloud library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bd7254-e493-4532-8bf2-d256ff63b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = (\n",
    "    pandas.concat([pandas.DataFrame(terms[t],columns='weight term'.split()) for t in terms])\n",
    "\n",
    "    # Delete recurrent index\n",
    "    .reset_index(drop=True)\n",
    "\n",
    "    # Weight is integer\n",
    "    .astype(dict(weight=pandas.Int8Dtype()))\n",
    "\n",
    "    # Fill undefined weights with a random number\n",
    "    .assign(\n",
    "        weight=lambda table: table.weight.combine_first(pandas.Series(numpy.random.default_rng().integers(1, 8, size=len(table.weight))))\n",
    "    )\n",
    "\n",
    "    # Convert to format usable by wordcloud library: {term: weight}\n",
    "    .set_index('term')\n",
    "    .to_dict()\n",
    ")\n",
    "# terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835d55c-330c-4e9b-83c6-b1f5fa23c4c4",
   "metadata": {},
   "source": [
    "Make the word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934c4b5-a761-4726-80b3-da41a29dc6e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cloud=wordcloud.WordCloud(**wordcloud_config)\n",
    "cloud.generate_from_frequencies(terms['weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4890c2-190b-4172-949d-3f8e065b7f14",
   "metadata": {},
   "source": [
    "Display it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6424509-605b-49c2-be50-6a0e37b95480",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.pyplot.figure(figsize=(16,9))\n",
    "matplotlib.pyplot.imshow(cloud, interpolation=\"bilinear\")\n",
    "matplotlib.pyplot.axis(False)\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce0a24-8362-4b97-8a6a-7693b0e0c0d5",
   "metadata": {},
   "source": [
    "Save as SVG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e476c01-10fb-4335-9547-75ce8ab372d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data Science Word Cloud.svg\",\"w+\") as f:\n",
    "    f.write(cloud.to_svg(embed_font=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb18d102-5f3d-49b5-ad47-32c44b2d6af0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
